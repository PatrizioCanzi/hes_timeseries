{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "gather": {
     "logged": 1668019119633
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import holidays\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks, detrend\n",
    "\n",
    "import plotly.express as px \n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, make_scorer\n",
    "from sklearn.metrics import root_mean_squared_error , mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "gather": {
     "logged": 1668019210787
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def describe_time_series(df , col = None , hist_margin = 'rug' , hist_on = False ) :\n",
    "    ### takes a dataframe with a datetime index\n",
    "    ### returns\n",
    "    ##  summary statistics \n",
    "    ## plots \n",
    "\n",
    "    col_ts =  col if col != None else df.columns[0] \n",
    "    ts = df.loc[:, [col_ts] ]\n",
    "\n",
    "    ## CHECK TIMESTAMPS\n",
    "    continous_index = pd.date_range ( ts.index.min() , ts.index.max() ,  freq = ts.index.freq)\n",
    "    continous_dates_df = pd.DataFrame(index = continous_index ,\n",
    "                                      data = ({'cont_dates': continous_index }) )\n",
    "    \n",
    "    measures_per_timestamp = continous_dates_df.merge(ts , left_index= True , right_index= True , how = 'left').groupby('cont_dates').count()\n",
    "    measures_per_timestamp['problem'] = measures_per_timestamp[measures_per_timestamp != 1 ] \n",
    "\n",
    "    print(' DUPLICATE OR MISSING TIMESTAMPS' , measures_per_timestamp[measures_per_timestamp.problem == 1 ])   \n",
    "\n",
    "    ## CHECK NULL VALUES \n",
    "    print ('MISSING VALUES in ', ts.isnull().sum()[0], ',', (ts.isnull().sum()/ts.shape[0])[0] , ' %  TIMESTEPS' ) \n",
    "    print( 'NUMBER OF TIMESTEPS' , ts.shape[0])\n",
    "\n",
    "    ## PLOT TIMESERIES \n",
    "    line_plot  = px.line( data_frame= ts  , \n",
    "          x = ts.index , \n",
    "          y = str(col_ts) , \n",
    "          title = 'LINE PLOT ' + str(col_ts) )\n",
    "\n",
    "    ## DISTRIBUTION PLOT \n",
    "\n",
    "    histo = px.histogram( ts, x= str(col_ts),  marginal=hist_margin ) # can be `box`, `violin`\n",
    "    ## CHECK \n",
    "\n",
    "    yearly_summary = ts.resample('YS').agg( ['sum' ,'mean','min' , 'max' , 'std'])\n",
    "    \n",
    "    line_plot.show()\n",
    "    if hist_on == True: \n",
    "          histo.show()\n",
    "\n",
    "    print(yearly_summary)\n",
    "\n",
    "\n",
    "\n",
    "    return \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "gather": {
     "logged": 1668019119971
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def extract_time_features( df_in , holidays_on = True , feature_format = 'linear' ): \n",
    "    ## takes a dataframe with the index as a timeseries \n",
    "    ## gets back time related features in the dataframe \n",
    "    ## parameters : feature format : linear or sinusoidal \n",
    "\n",
    "\n",
    "    df = df_in.copy(deep=True) \n",
    "\n",
    "    df['is_weekend'] = (df.index.weekday > 4).astype(int)\n",
    "\n",
    "    if holidays_on == True:\n",
    "        country_holidays = holidays.Belgium()\n",
    "        df['dates'] = df.index \n",
    "        df['is_holiday'] = df.dates.apply( lambda x: x in country_holidays).astype(int)\n",
    "        df.drop( columns = 'dates' , inplace = True )\n",
    "\n",
    "        \n",
    "\n",
    "    if feature_format == 'linear': \n",
    "        df['hour'] =    df.index.hour\n",
    "        df['month'] =   df.index.month\n",
    "        df['weekday'] = df.index.weekday\n",
    "\n",
    "    if feature_format == 'sinusoidal':\n",
    "        df['hour_cos'] = np.cos( ( df.index.hour  ) / 23 * 2 * np.pi )\n",
    "        df['hour_sin'] = np.sin( ( df.index.hour  ) / 23 * 2 * np.pi )\n",
    "\n",
    "        df['month_cos'] = np.cos( df.index.month / 11 * 2 * np.pi )\n",
    "        df['month_sin'] = np.sin( df.index.month / 11 * 2 * np.pi )\n",
    "\n",
    "        \n",
    "        df['weekday_cos'] = np.cos( (df.index.weekday ) / 6 * 2 * np.pi )\n",
    "        df['weekday_sin'] = np.sin( (df.index.weekday ) / 6 * 2 * np.pi )\n",
    "\n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "gather": {
     "logged": 1668019120143
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def create_lags(df_in , col = None , n_lags = [ 96 , 96*2 ] , na_strategy = 'bfill' , verbose = False  ):\n",
    "\n",
    "    ## Takes a dataframe and a column and a list of lags to be performed \n",
    "    ## strategy to handle na_shall_also_be_specified \n",
    "\n",
    "    df = df_in.copy(deep = True )\n",
    " \n",
    "    col_ts =  col if col != None else df.columns[0] \n",
    "\n",
    "    for l in n_lags:\n",
    "\n",
    "        df['lag_'+str(l)+'_'+col_ts] = df[col_ts].shift(l)\n",
    "        \n",
    "    df.fillna( method = na_strategy  , inplace = True )\n",
    "    if verbose == True : \n",
    "        print(df.columns)\n",
    "\n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "gather": {
     "logged": 1668019120298
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def plot_all_columns( df_input , graph_title  ) :\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for c in df_input.columns:\n",
    "        fig.add_trace( go.Scatter( x = df_input.index , y = df_input[c] , name = str(c) ))\n",
    "\n",
    "    fig.update_layout(title = graph_title)\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "gather": {
     "logged": 1668019120540
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "##df_index = pd.date_range('2019-01-01' ,'2022-01-01' , freq = '15min' )  \n",
    "##df_values = 10*( np.sin( df_index.hour ))\n",
    "\n",
    "##df = pd.DataFrame( index = df_index , data = {'measure' : 1000*( np.sin( df_index.hour )),\n",
    "##                                            'temperature' : 4*( np.cos( df_index.hour )) })           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "gather": {
     "logged": 1668019120701
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "PAR= { 'TARGET_VALUE' : 'load' , \n",
    "       'TRAIN_START' : '2019-01-01' , \n",
    "       'TRAIN_END'   :  '2023-01-01' , \n",
    "       'TEST_END' :     '2023-12-31'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Formulation du Problème\n",
    "\n",
    "### Construire un modele pour prevoir tous les valeurs horaires de consommations avec 24 heures d'avance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Le dataset\n",
    "\n",
    "Entsoe: données de consommation des réseaux europeens, disponibles d'une maniere publique.\n",
    "Use case: Charge electrique Suisse\n",
    "\n",
    "https://transparency.entsoe.eu/load-domain/r2/totalLoadR2/show \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "load = pd.read_csv('..\\\\data\\\\curated_data\\\\load_clean.csv', parse_dates = [2])\n",
    "\n",
    "df  = load.copy(deep = True)\n",
    "df.set_index('dt' , inplace = True) \n",
    "df.drop( columns= 'load_forecast',inplace = True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019222231
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "describe_time_series(df, col = 'load')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Facteurs de dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019222467
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prep_df  =( df.pipe(  extract_time_features , feature_format = 'sinusoidal' )\n",
    "              .pipe(  create_lags , col = PAR['TARGET_VALUE'], n_lags = [24*7, 24*1,24*2] ))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019222681
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019223095
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "plot_all_columns(prep_df[prep_df.index > '2020-04-01 00:00:00'].head(96 * 7)  , graph_title= 'Features pour une semaine ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019223292
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "px.bar( prep_df.corr()['load'].sort_values() , title = 'Correlations avec consumption MW' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "gather": {
     "logged": 1668019223502
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df['temperature'] = 12 + 10 * np.cos( df.index.month / 12 * 2 * np.pi ) + 3 *  np.sin( df.index.hour / 24 * 2 * np.pi ) + 3*random.uniform(-1, 1)\n",
    "#describe_time_series( df , col = 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Separer dataset train et test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "gather": {
     "logged": 1668019223703
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "train  = prep_df[ (prep_df.index >= PAR['TRAIN_START']) &  (prep_df.index <= PAR['TRAIN_END'])]\n",
    "test   = prep_df[ (df.index > PAR['TRAIN_END'] )  & ( prep_df.index < PAR['TEST_END'])]\n",
    "\n",
    "y_train  = train[PAR['TARGET_VALUE']]\n",
    "X_train  = train.drop(columns = PAR['TARGET_VALUE'] ) \n",
    "\n",
    "y_test  = test[PAR['TARGET_VALUE']]\n",
    "X_test  = test.drop(columns = PAR['TARGET_VALUE'] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019227683
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "fig.add_trace( go.Scatter( x = y_train.index , y = y_train.values , name = 'Train'))\n",
    "fig.add_trace( go.Scatter( x = y_test.index ,  y = y_test.values ,  name = 'Test'))\n",
    "fig.update_layout( title = 'TRAIN - TEST')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Avant des modeles complexes: une baseline solide ! \n",
    "On note une periodicité horaire et une difference jour et jour \n",
    "un modele simple mais efficace pourrait etre que la consommation de demain à l'heure X est la consommation il y a 7 jour  à la meme heure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "gather": {
     "logged": 1668019227848
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "y_naive= prep_df[PAR['TARGET_VALUE']].shift( 24 * 7 )\n",
    "y_naive_test = y_naive[y_naive.index.isin(y_test.index)]\n",
    "y_naive_train= y_naive[y_naive.index.isin(y_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019229531
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    "fig.add_trace( go.Scatter( x = y_test.index ,  y = y_test ,  name = 'Test'))\n",
    "fig.add_trace( go.Scatter( x = y_naive_test.index ,  y = y_naive_test ,  name = 'NAIVE 7 jours'))\n",
    "\n",
    "fig.update_layout(title = 'NAIVE MODEL VS TEST SET')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019229671
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print( np.round( 100* np.mean( np.abs( y_naive_test - y_test ) / y_test ) ,3 ) , 'MAPE NAIVE 7 jours' )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019230078
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "fig_hist = go.Figure() \n",
    "fig_hist = px.histogram(x =  y_naive_test - y_test  , title = 'Distribution des erreurs' )\n",
    "fig_hist.add_trace( go.Scatter( x = [0,0] , y = [0, 1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Augmenter la complexité Graduellement\n",
    "\n",
    "1. Modele de regression lineaire\n",
    "2. Modele Random Forest\n",
    "\n",
    "D'autres choix sont possibles:\n",
    "- Travailler sur les parametres des modeles \n",
    "- Travailler sur la forme du probleme en time serie \n",
    "- Travailler avec des modeles plus complexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019230253
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "linear_regression_pipeline = Pipeline(\n",
    "[\n",
    "('scaler' ,        StandardScaler() ), \n",
    "('LR' ,            LinearRegression())] ) \n",
    "\n",
    "linear_regression_pipeline.fit(X_train , y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019238876
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "random_forest_pipeline = Pipeline(\n",
    "[\n",
    "('scaler' ,        StandardScaler() ), \n",
    "('RF' ,            RandomForestRegressor(n_estimators=50 ))] ) \n",
    "\n",
    "random_forest_pipeline.fit(X_train , y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019239358
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "random_forest_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Work on the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "gather": {
     "logged": 1668019239514
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cv_params = { 'RF__max_depth' : [6,10] , \n",
    "             'RF__n_estimators' : [100,120 ]  }\n",
    "\n",
    "## Cross validation \n",
    "ts_cv  = TimeSeriesSplit(n_splits = 2 , gap = 24 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "gather": {
     "logged": 1668019239657
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "grid_search_model = GridSearchCV( \n",
    "                            estimator= random_forest_pipeline , \n",
    "                            param_grid= cv_params, \n",
    "                            cv = ts_cv  , \n",
    "                            scoring = make_scorer(mean_squared_error, greater_is_better= False) ,\n",
    "                            return_train_score = True , \n",
    "                            verbose = 4, ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019372843
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019373043
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Compute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "gather": {
     "logged": 1668019373303
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "results_train = pd.DataFrame(y_train)\n",
    "results_train['pred_naive_'+PAR['TARGET_VALUE']] = y_naive_train \n",
    "results_train['pred_lr_'+PAR['TARGET_VALUE']] = linear_regression_pipeline.predict(X_train)\n",
    "results_train['pred_rf_'+PAR['TARGET_VALUE'] ] = random_forest_pipeline.predict(X_train)\n",
    "results_train['pred_rf_cv_'+PAR['TARGET_VALUE'] ] = grid_search_model.predict(X_train)\n",
    "results_train['set'] = 'train'\n",
    "\n",
    "\n",
    "results = pd.DataFrame(y_test)\n",
    "results['pred_naive_'+PAR['TARGET_VALUE']] = y_naive_test \n",
    "results['pred_lr_'+PAR['TARGET_VALUE']] = linear_regression_pipeline.predict(X_test)\n",
    "results['pred_rf_'+PAR['TARGET_VALUE'] ] = random_forest_pipeline.predict(X_test)\n",
    "results['pred_rf_cv_'+PAR['TARGET_VALUE'] ] = grid_search_model.predict(X_test)\n",
    "\n",
    "results['set'] = 'test' \n",
    "\n",
    "res = pd.concat( [ results_train , results  ], ignore_index = True ).bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019381190
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "plot_all_columns(results , graph_title = 'Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "gather": {
     "logged": 1668019381387
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "res_set = []\n",
    "models = []\n",
    "mape_error = []\n",
    "rmse_error  =[]\n",
    "mse_error = []\n",
    "\n",
    "for c in res.columns[1:-1]:\n",
    "    for s in res.set.unique(): \n",
    "        \n",
    "        r_df = res[res.set == s] \n",
    "\n",
    "        res_set.append( s )\n",
    "        models.append( c )\n",
    "        mape_error.append( np.round( 100*mean_absolute_percentage_error( r_df[PAR['TARGET_VALUE']].values , r_df[c].values ) ,  3 )) \n",
    "        rmse_error.append( np.round( root_mean_squared_error( r_df[PAR['TARGET_VALUE']].values , r_df[c].values ) , 3 ))\n",
    "        mse_error.append(  np.round( mean_squared_error( r_df[PAR['TARGET_VALUE']].values , r_df[c].values ) , 3 ))\n",
    "\n",
    "metrics_df = pd.DataFrame( data = {\n",
    "                             'result_set' : res_set, \n",
    "                             'models' : models, \n",
    "                             'mape': mape_error , \n",
    "                             'rmse':rmse_error,\n",
    "                             'mse': mse_error })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Metriques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1668019381573
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "metrics_df.pivot(columns= 'result_set' , index= 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_columns(load, 'Available prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_test =load[ load.dt.dt.year == 2023 ]\n",
    "\n",
    "print( 100*mean_absolute_percentage_error( load_test[PAR['TARGET_VALUE']].values , load_test['load_forecast'].values ))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
